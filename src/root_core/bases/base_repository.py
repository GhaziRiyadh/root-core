import json
from typing import (
    Any,
    Callable,
    Dict,
    Generic,
    List,
    Optional,
    Type,
    TypeVar,
    Union,
)
from datetime import date, datetime, time
from sqlmodel import SQLModel, func, or_, select
from sqlmodel.ext.asyncio.session import AsyncSession
from sqlalchemy.exc import IntegrityError, SQLAlchemyError
from pydantic import BaseModel

from root_core.response import schemas
from root_core.config import PermissionAction, settings
from root_core.apps.auth.utils.utils import auth

T = TypeVar("T", bound=SQLModel)
CreateSchemaType = TypeVar("CreateSchemaType", bound=BaseModel)
UpdateSchemaType = TypeVar("UpdateSchemaType", bound=BaseModel)


def json_safe(o):
    if isinstance(o, (datetime, date, time)):
        return o.isoformat()
    raise TypeError


class RepositoryError(Exception):
    """Custom exception for repository errors."""

    pass


class BaseRepository(Generic[T]):
    model: Type[T]
    _options: List[Any] = []
    get_session: Callable[..., AsyncSession]
    _search_fields: List[str] = []
    _permission_name: str

    def __init__(self, get_session: Callable[..., AsyncSession]):
        self.get_session = get_session

    def _handle_db_error(self, error: SQLAlchemyError, operation: str) -> None:
        """Handle database errors and raise appropriate exceptions."""
        if isinstance(error, IntegrityError):
            raise RepositoryError(
                f"Database integrity error during {operation}: {error}"
            ) from error
        else:
            raise RepositoryError(
                f"Database error during {operation}: {error}"
            ) from error

    def _build_select_stmt(self, include_deleted: bool = False, **filters) -> Any:
        """Build select statement with optional filters and soft delete handling."""
        stmt = select(self.model).options(*self._options)

        # Apply soft delete filter if applicable
        if not include_deleted and hasattr(self.model, "is_deleted"):
            stmt = stmt.where(self.model.is_deleted == False)  # type: ignore

        # Apply additional filters
        for field, value in filters.items():
            if field == "query" and value:
                search_conditions = [
                    getattr(self.model, field).ilike(f"%{value}%")
                    for field in self._search_fields
                    if hasattr(self.model, field)
                ]
                stmt = (
                    stmt.where(or_(*search_conditions)) if search_conditions else stmt  # type: ignore
                )
            elif hasattr(self.model, field):
                # Allow custom filter methods on the repository
                custom_filter = getattr(self, f"filter_{field}", None)
                if callable(custom_filter):
                    stmt = custom_filter(stmt, value)
                else:
                    model_field = getattr(self.model, field, None)
                    if model_field is not None:
                        if isinstance(value, list):
                            stmt = stmt.where(model_field.in_(value))  # type: ignore
                        elif value is None:
                            stmt = stmt.where(model_field.is_(None))  # type: ignore
                        else:
                            stmt = stmt.where(model_field == value)  # type: ignore

        return stmt

    # ----------------- CRUD ----------------- #
    async def get(
        self, item_id: int, include_deleted: bool = False, **filters
    ) -> Optional[T]:
        """Get a single item by ID with optional additional filters."""
        async with self.get_session() as db:
            try:
                stmt = self._build_select_stmt(
                    include_deleted=include_deleted, **filters
                )
                stmt = stmt.where(self.model.id == item_id)  # type: ignore

                result = await db.exec(stmt)
                return result.first()
            except SQLAlchemyError as e:
                self._handle_db_error(e, "get")

    async def get_all(
        self, include_deleted: bool = False, **filters
    ) -> List[T]:  # type:ignore
        """Get all items, optionally including deleted ones."""
        async with self.get_session() as db:
            try:
                stmt = self._build_select_stmt(
                    include_deleted=include_deleted,
                    **filters,
                )
                result = await db.exec(stmt)
                return result.all()
            except SQLAlchemyError as e:
                self._handle_db_error(e, "get_all")

    async def get_one(self, **filters) -> Optional[T]:
        """Get a single item matching the filters."""
        async with self.get_session() as db:
            try:
                stmt = self._build_select_stmt(**filters)
                result = await db.exec(stmt)
                return result.first()
            except SQLAlchemyError as e:
                self._handle_db_error(e, "get_one")

    async def get_many(
        self,
        *,
        skip: int = 0,
        limit: int = 100,
        include_deleted: bool = False,
        **filters,
    ) -> List[T]:  # type:ignore
        """Get multiple items with filtering and pagination."""
        async with self.get_session() as db:
            try:
                stmt = self._build_select_stmt(
                    include_deleted=include_deleted, **filters
                )
                stmt = stmt.offset(skip).limit(limit)

                result = await db.exec(stmt)
                return result.all()
            except SQLAlchemyError as e:
                self._handle_db_error(e, "get_many")

    async def list(
        self,
        page: int = 1,
        per_page: int = 10,
        include_deleted: bool = False,
        sort_by: str = "id",
        sort_order: str = "desc",
        **filters,
    ) -> schemas.PaginatedResponse:  # type:ignore
        """Get paginated list of items."""
        if page < 1:
            page = 1
        if per_page < 1 or per_page > 100:
            per_page = 10

        async with self.get_session() as db:
            try:
                offset = (page - 1) * per_page

                # Build base query
                stmt = self._build_select_stmt(
                    include_deleted=include_deleted, **filters
                )

                # Get total count
                count_stmt = select(func.count()).select_from(stmt.subquery())
                total_result = await db.exec(count_stmt)
                total = total_result.one()

                # Apply sorting
                if hasattr(self.model, sort_by):
                    sort_column = getattr(self.model, sort_by)
                    if sort_order.lower() == "desc":
                        stmt = stmt.order_by(sort_column.desc())
                    else:
                        stmt = stmt.order_by(sort_column.asc())

                # Get paginated items
                result = await db.exec(stmt.offset(offset).limit(per_page))
                items = result.all()

                # Calculate pages
                pages = (total + per_page - 1) // per_page  # Ceiling division

                return schemas.PaginatedResponse(
                    success=True,
                    data=items,
                    total=total,
                    page=page,
                    per_page=per_page,
                    pages=pages,
                    message="Items retrieved successfully",
                )
            except SQLAlchemyError as e:
                self._handle_db_error(e, "list")

    async def create(
        self, obj_in: Union[Dict[str, Any], CreateSchemaType]
    ) -> T:  # type:ignore
        """Create a new item."""
        if isinstance(obj_in, BaseModel):
            obj_in = obj_in.model_dump(exclude_unset=True)

        async with self.get_session() as db:
            try:
                obj = self.model(**obj_in)  # type: ignore
                db.add(obj)
                await db.flush()

                await self._add_log(
                    action=PermissionAction.READ,
                    record_id=obj.id,  # type:ignore
                    new_data=json.loads(
                        json.dumps(
                            obj.model_dump(exclude={"is_deleted", "id"}),
                            default=json_safe,
                        )
                    ),
                    db=db,
                )

                await db.commit()
                await db.refresh(obj)
                return obj

            except IntegrityError as e:
                await db.rollback()
                self._handle_db_error(e, "create")
            except SQLAlchemyError as e:
                await db.rollback()
                self._handle_db_error(e, "create")

    async def create_many(
        self, objects_in: List[Union[Dict[str, Any], BaseModel]]
    ) -> List[T]:  # type:ignore
        """Create multiple items at once."""
        objects_data = [
            obj.model_dump(exclude_unset=True) if isinstance(obj, BaseModel) else obj
            for obj in objects_in
        ]

        async with self.get_session() as db:
            try:
                objects = [self.model(**data) for data in objects_data]  # type: ignore
                db.add_all(objects)
                for item in objects:
                    await self._add_log(
                        action=PermissionAction.CREATE,
                        record_id=item.id,  # type:ignore
                        new_data=json.loads(
                            json.dumps(
                                item.model_dump(exclude={"is_deleted", "id"}),
                                default=json_safe,
                            )
                        ),
                        db=db,
                    )

                await db.commit()

                # Refresh all objects
                for obj in objects:
                    await db.refresh(obj)

                return objects
            except SQLAlchemyError as e:
                await db.rollback()
                self._handle_db_error(e, "create_many")

    async def update(
        self,
        item_id: Any,
        obj_in: Union[Dict[str, Any], BaseModel],
        exclude_unset: bool = True,
    ) -> Optional[T]:
        """Update an existing item."""
        if isinstance(obj_in, BaseModel):
            update_data = obj_in.model_dump(exclude_unset=exclude_unset)
        else:
            update_data = obj_in

        # Remove ID from update data to prevent changing primary key
        update_data.pop("id", None)

        if not update_data:
            raise RepositoryError("No data provided for update")

        async with self.get_session() as db:
            try:
                db_obj = await db.get(self.model, item_id, options=self._options)
                if not db_obj:
                    return None

                await self._add_log(
                    action=PermissionAction.UPDATE,
                    record_id=db_obj.id,  # type:ignore
                    new_data=json.loads(
                        json.dumps(
                            {
                                **db_obj.model_dump(exclude={"is_deleted", "id"}),
                                **update_data,
                            },
                            default=json_safe,
                        )
                    ),
                    old_data=json.loads(
                        json.dumps(
                            db_obj.model_dump(exclude={"is_deleted", "id"}),
                            default=json_safe,
                        )
                    ),
                    db=db,
                )

                for key, value in update_data.items():
                    if value is not None:
                        if not hasattr(self, f"update_{key}"):
                            if hasattr(db_obj, key) and key != "id":
                                setattr(db_obj, key, value)
                        else:
                            await self.__getattribute__(f"update_{key}")(
                                db,
                                db_obj,
                                value,
                            )

                await db.commit()
                await db.refresh(db_obj)
                return db_obj
            except SQLAlchemyError as e:
                print(e)
                await db.rollback()
                self._handle_db_error(e, "update")

    async def exists(
        self, item_id: Any, include_deleted: bool = False
    ) -> bool:  # type:ignore
        """Check if an item exists."""
        async with self.get_session() as db:
            try:
                stmt = select(self.model.id).where(self.model.id == item_id).options(*self._options)  # type: ignore
                if not include_deleted and hasattr(self.model, "is_deleted"):
                    stmt = stmt.where(self.model.is_deleted == False)  # type: ignore

                result = await db.exec(stmt)
                return result.first() is not None
            except SQLAlchemyError as e:
                self._handle_db_error(e, "exists")

    async def count(
        self, include_deleted: bool = False, **filters
    ) -> int:  # type:ignore
        """Count items matching optional filters."""
        async with self.get_session() as db:
            try:
                stmt = self._build_select_stmt(
                    include_deleted=include_deleted, **filters
                )
                count_stmt = select(func.count()).select_from(stmt.subquery())
                result = await db.exec(count_stmt)
                return result.one()
            except SQLAlchemyError as e:
                self._handle_db_error(e, "count")

    # ----------------- DELETE / RESTORE ----------------- #
    async def soft_delete(self, item_id: Any) -> bool:  # type:ignore
        """Mark item as deleted instead of removing it."""
        if not hasattr(self.model, "is_deleted"):
            raise AttributeError("Model must have 'is_deleted' field for soft delete")

        async with self.get_session() as db:
            try:
                db_obj = await db.get(self.model, item_id)
                if not db_obj:
                    return False

                setattr(db_obj, "is_deleted", True)
                await self._add_log(
                    action=PermissionAction.DELETE,
                    record_id=db_obj.id,  # type:ignore
                    new_data={"is_deleted": True},
                    old_data={"is_deleted": False},
                    db=db,
                )
                await db.commit()
                return True
            except SQLAlchemyError as e:
                print(e)
                await db.rollback()
                self._handle_db_error(e, "soft_delete")

    async def restore(self, item_id: Any) -> bool:  # type:ignore
        """Restore a soft deleted item."""
        if not hasattr(self.model, "is_deleted"):
            raise AttributeError("Model must have 'is_deleted' field for restore")

        async with self.get_session() as db:
            try:
                db_obj = await db.get(self.model, item_id)
                if not db_obj:
                    return False

                await self._add_log(
                    action=PermissionAction.RESTORE,
                    record_id=db_obj.id,  # type:ignore
                    new_data={"is_deleted": False},
                    old_data={"is_deleted": True},
                    db=db,
                )
                setattr(db_obj, "is_deleted", False)
                await db.commit()
                return True
            except SQLAlchemyError as e:
                await db.rollback()
                self._handle_db_error(e, "restore")

    async def force_delete(self, item_id: Any) -> bool:  # type:ignore
        """Permanently delete the item from DB."""
        async with self.get_session() as db:
            try:
                db_obj = await db.get(self.model, item_id)
                if not db_obj:
                    return False

                await self._add_log(
                    action=PermissionAction.FORCE_DELETE,
                    record_id=db_obj.id,  # type:ignore
                    old_data=db_obj.model_dump_json(),
                    db=db,
                )
                await db.delete(db_obj)
                await db.commit()
                return True
            except SQLAlchemyError as e:
                await db.rollback()
                self._handle_db_error(e, "force_delete")

    async def force_delete_many(self, item_ids: List[Any]) -> bool:  # type:ignore
        """Permanently delete multiple items from DB."""
        async with self.get_session() as db:
            try:
                result = await db.exec(
                    select(self.model).where(self.model.id.in_(item_ids)).options(*self._options)  # type: ignore
                )
                objects = result.all()

                for obj in objects:
                    await db.delete(obj)
                    await self._add_log(
                        action=PermissionAction.FORCE_DELETE,
                        record_id=obj.id,  # type:ignore
                        old_data=obj.model_dump_json(),
                        db=db,
                    )

                await db.commit()
                return True
            except SQLAlchemyError as e:
                await db.rollback()
                self._handle_db_error(e, "force_delete_many")

    async def bulk_create(self, items: List[T]) -> List[T]:  # type:ignore
        """Bulk create items."""
        async with self.get_session() as db:
            try:
                db.add_all(items)
                await db.flush()
                for item in items:
                    await self._add_log(
                        action=PermissionAction.CREATE,
                        record_id=item.id,  # type:ignore
                        new_data=item.model_dump(exclude={"is_deleted", "id"}),
                        db=db,
                    )

                await db.commit()
                for item in items:
                    await db.refresh(item)

                return items
            except SQLAlchemyError as e:
                await db.rollback()
                self._handle_db_error(e, "bulk_create")

    async def bulk_update(self, items: List[T]) -> List[T]:  # type:ignore
        """Bulk update items."""
        async with self.get_session() as db:
            try:
                for item in items:
                    await db.merge(item)
                    await self._add_log(
                        action=PermissionAction.UPDATE,
                        record_id=item.id,  # type:ignore
                        new_data=item.model_dump(exclude={"is_deleted", "id"}),
                        db=db,
                    )
                await db.commit()
                for item in items:
                    await db.refresh(item)

                return items
            except SQLAlchemyError as e:
                await db.rollback()
                self._handle_db_error(e, "bulk_update")

    async def search(
        self, query: str, search_fields: List[str] = []
    ) -> schemas.PaginatedResponse:  # type:ignore
        """Search items based on query string across predefined search fields."""
        if not search_fields:
            search_fields = self._search_fields

        async with self.get_session() as db:
            try:
                stmt = select(self.model).options(*self._options)

                # Apply soft delete filter if applicable
                if hasattr(self.model, "is_deleted"):
                    stmt = stmt.where(self.model.is_deleted == False)  # type: ignore

                # Build search conditions
                search_conditions = [
                    getattr(self.model, field).ilike(f"%{query}%")
                    for field in search_fields
                    if hasattr(self.model, field)
                ]

                if search_conditions:
                    from sqlmodel import or_

                    stmt = stmt.where(or_(*search_conditions))

                result = await db.exec(stmt)
                items = result.all()
                total = len(items)

                return schemas.PaginatedResponse[T](
                    success=True,
                    data=list(items),
                    total=total,
                    page=1,
                    per_page=total,
                    pages=1,
                    message="Search completed successfully",
                )
            except SQLAlchemyError as e:
                self._handle_db_error(e, "search")

    async def bulk_delete(self, ids: List[int]):
        """Bulk soft delete items by IDs."""
        if not hasattr(self.model, "is_deleted"):
            raise AttributeError("Model must have 'is_deleted' field for bulk delete")

        async with self.get_session() as db:
            try:
                result = await db.exec(
                    select(self.model).where(self.model.id.in_(ids))  # type: ignore
                )
                objects = result.all()

                for obj in objects:
                    setattr(obj, "is_deleted", not getattr(obj, "is_deleted", True))
                    await self._add_log(
                        action=(
                            PermissionAction.DELETE if getattr(obj, "is_deleted", True) else PermissionAction.RESTORE
                        ),
                        record_id=obj.id,  # type:ignore
                        new_data={"is_deleted": getattr(obj, "is_deleted", True)},
                        old_data={"is_deleted": not getattr(obj, "is_deleted", True)},
                        db=db,
                    )

                await db.commit()

                for obj in objects:
                    await db.refresh(obj)

                return True
            except SQLAlchemyError as e:
                await db.rollback()
                self._handle_db_error(e, "bulk_delete")

    async def get_logs(
        self,
        page: int = 1,
        per_page: int = 10,
        include_deleted: bool = False,
        sort_by: str = "id",
        sort_order: str = "desc",
        **filters,
    ) -> schemas.PaginatedResponse:
        """Retrieve logs for a specific user or action."""
        try:
            # Dynamically import log model
            log_module = __import__(settings.LOG_MODEL, fromlist=["Log"])
            Log = getattr(log_module, "Log")

            stmt = select(Log).where(
                Log.table_name
                == getattr(self.model, "__tablename__", self.model.__name__)
            )
            if hasattr(Log, "is_deleted"):
                stmt = stmt.where(Log.is_deleted == include_deleted)

            # Apply filters
            for field, value in filters.items():
                if hasattr(Log, field):
                    model_field = getattr(Log, field, None)
                    if model_field is not None:
                        if isinstance(value, list):
                            stmt = stmt.where(model_field.in_(value))  # type: ignore
                        elif value is None:
                            stmt = stmt.where(model_field.is_(None))  # type: ignore
                        else:
                            stmt = stmt.where(model_field == value)  # type: ignore
            # Get total count
            count_stmt = select(func.count()).select_from(stmt.subquery())

            async with self.get_session() as db:
                total_result = await db.exec(count_stmt)
                total = total_result.one()

                # Apply sorting
                if hasattr(Log, sort_by):
                    sort_column = getattr(Log, sort_by)
                    if sort_order.lower() == "desc":
                        stmt = stmt.order_by(sort_column.desc())
                    else:
                        stmt = stmt.order_by(sort_column.asc())

                # Pagination
                if page < 1:
                    page = 1
                if per_page < 1 or per_page > 100:
                    per_page = 10
                offset = (page - 1) * per_page
                stmt = stmt.offset(offset).limit(per_page)
                result = await db.exec(stmt)
                items = result.all()
                pages = (total + per_page - 1) // per_page  # Ceiling division
                return schemas.PaginatedResponse(
                    success=True,
                    data=items,  # type:ignore
                    total=total,
                    page=page,
                    per_page=per_page,
                    pages=pages,
                    message="Logs retrieved successfully",
                )
        except Exception as e:
            raise e

    async def _add_log(
        self,
        action: PermissionAction,
        old_data: Optional[Any] = None,
        new_data: Optional[Any] = None,
        record_id: int = 0,
        user_id: Optional[int] = None,
        db: Optional[AsyncSession] = None,
    ):
        """Add a log entry for repository actions."""
        user = auth().user
        if user and hasattr(user, "id"):
            user_id = user.id  # type: ignore

        async def saveLog(session):
            # Dynamically import log model
            log_module = __import__(settings.LOG_MODEL, fromlist=["Log"])
            Log = getattr(log_module, "Log")

            log_entry = Log(
                table_name=getattr(self.model, "__tablename__", self.model.__name__),
                record_id=record_id,
                action=action,
                old_data=old_data,
                new_data=new_data,
                user_id=user_id,
                ip_address=auth().ip_address,
                user_agent=auth().user_agent,
            )

            session.add(log_entry)
            # await session.commit()

        if db:
            await saveLog(db)
        else:
            async with self.get_session() as db:
                await saveLog(db)
